{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, we'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. we'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  we'll build a convolutional, max pooling, dropout, and fully connected layers.  At the end, we'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf009c3b00>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, `normalize` function  take in image data, `x`, and return it as a normalized Numpy array. The values is  in the range of 0 to 1, inclusive.  The return object is the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print(x.shape)\n",
    "    normalized_images=np.zeros((x.shape))\n",
    "    nbr_images=x.shape[0]\n",
    "    min_image,max_image=x.min(),x.max()\n",
    "    #print(max_image)\n",
    "    for image in range(nbr_images):\n",
    "        normalized_images[image,...]=((x[image,...]-min_image)-float(min_image))/(float(max_image-min_image))\n",
    "    return normalized_images\n",
    "\n",
    "\n",
    "\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, we'll be implementing a function for preprocessing.  This time, we'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Function returns the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function  return the same encoding for each value between each call to `one_hot_encode`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "lb=None\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    global lb\n",
    "    if lb is None:\n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        lb.fit(x)\n",
    "    encodings = lb.transform(x)\n",
    "    return encodings\n",
    "\n",
    "\n",
    "\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, we'll build each layer into a function. \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. we'll Implement the following functions\n",
    "*  `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "*  `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "*  `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.placeholder(tf.float32, shape=[None]+list(image_shape),name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "   \n",
    "    #print(n_classes)\n",
    "    return  tf.placeholder(tf.float32, shape=[None,n_classes],name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return  tf.placeholder(tf.float32, shape=(None),name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, we'll  implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape=[conv_ksize[0], conv_ksize[1], ((x_tensor.get_shape())[3]), conv_num_outputs]\n",
    "    print((list(x_tensor.get_shape())[3]))\n",
    "    weights =tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[3], conv_num_outputs],\n",
    "                                            mean=0.0,stddev = .1))\n",
    "    bias=tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    \n",
    "    x = tf.nn.conv2d(x_tensor, weights, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, bias)\n",
    "    x=  tf.nn.relu(x)\n",
    "    \n",
    "    output=tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "    return output \n",
    "\n",
    "\n",
    "\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Here we'll Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_tensor_shape=( x_tensor.get_shape().as_list())\n",
    "    x_tensor_ht=x_tensor_shape[1]\n",
    "    x_tensor_wt=x_tensor_shape[2]\n",
    "    x_tensor_channels=x_tensor_shape[3]\n",
    "    pool2_flat = tf.reshape(x_tensor, [-1, x_tensor_ht *x_tensor_wt*x_tensor_channels])\n",
    "    return pool2_flat\n",
    "\n",
    "\n",
    "\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "IHere we'll mplement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    x_tensor_shape=np.array(x_tensor.get_shape().as_list()[1:]).prod()\n",
    "    \n",
    "    weights =tf.Variable(tf.truncated_normal([x_tensor_shape, num_outputs],mean=0.0,stddev = .1))\n",
    "    biases=tf.Variable(tf.zeros(num_outputs))\n",
    "    c1 = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    \n",
    "    c1 = tf.nn.relu(c1)\n",
    "    \n",
    "    return c1\n",
    "\n",
    "\n",
    "\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "we'll Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_tensor_shape=np.array(x_tensor.get_shape().as_list()[1:]).prod()\n",
    "    print(x_tensor_shape)\n",
    "    weights =tf.Variable(tf.truncated_normal([x_tensor_shape, num_outputs],mean=0.0,stddev = .1))\n",
    "    biases=tf.Variable(tf.zeros(num_outputs))\n",
    "    c1 = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    return c1\n",
    "\n",
    "\n",
    "\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "we'll Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "16\n",
      "250\n",
      "3\n",
      "16\n",
      "250\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x,\n",
    "                           conv_num_outputs=16,\n",
    "                           conv_ksize=[5,5],\n",
    "                           conv_strides=[1,1],\n",
    "                           pool_ksize=[3,3],\n",
    "                           pool_strides=[2,2])\n",
    "    \n",
    "    conv = conv2d_maxpool(conv,\n",
    "                           conv_num_outputs=32,\n",
    "                           conv_ksize=[5,5],\n",
    "                           conv_strides=[1,1],\n",
    "                           pool_ksize=[3,3],\n",
    "                           pool_strides=[2,2])\n",
    "    \n",
    "#     conv = conv2d_maxpool(conv,\n",
    "#                             conv_num_outputs=64,\n",
    "#                             conv_ksize=[5,5],\n",
    "#                             conv_strides=[1,1],\n",
    "#                             pool_ksize=[3,3],\n",
    "#                             pool_strides=[2,2])\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flattened=flatten(conv)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fully_c= fully_conn(flattened,512)\n",
    "    fully_c= fully_conn(fully_c,250)\n",
    "    #fully_c= fully_conn(fully_c,50)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    fully_c=tf.nn.dropout(fully_c,keep_prob)\n",
    "    output_cn=output(fully_c, 10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_cn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "We'll Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                keep_prob: keep_probability})\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "We'll Implement the function `print_stats` to print loss and validation accuracy. We'll Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss=sess.run(cost,feed_dict={x:valid_features,\n",
    "                            y:valid_labels,\n",
    "                            keep_prob:1})\n",
    "    \n",
    "    valid_acc=sess.run(accuracy,feed_dict={x:valid_features,\n",
    "                            y:valid_labels,\n",
    "                            keep_prob:1})\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "We'll Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 75\n",
    "batch_size = 256\n",
    "keep_probability = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     1.9453 Validation Accuracy: 0.319400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.6291 Validation Accuracy: 0.410600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.5037 Validation Accuracy: 0.453200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.4132 Validation Accuracy: 0.493600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.3927 Validation Accuracy: 0.514200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.3337 Validation Accuracy: 0.527400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.3034 Validation Accuracy: 0.537200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.3498 Validation Accuracy: 0.525200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.3351 Validation Accuracy: 0.540600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.3110 Validation Accuracy: 0.549400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.3274 Validation Accuracy: 0.541800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.3446 Validation Accuracy: 0.546400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.3870 Validation Accuracy: 0.540400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.4308 Validation Accuracy: 0.541000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.4158 Validation Accuracy: 0.550000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.4125 Validation Accuracy: 0.565800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.4593 Validation Accuracy: 0.560000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.4545 Validation Accuracy: 0.555800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.6217 Validation Accuracy: 0.526800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.6108 Validation Accuracy: 0.543200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.5684 Validation Accuracy: 0.560000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.7514 Validation Accuracy: 0.534400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.7895 Validation Accuracy: 0.540800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.6858 Validation Accuracy: 0.556400\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.7469 Validation Accuracy: 0.546000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.8842 Validation Accuracy: 0.552000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.9133 Validation Accuracy: 0.549800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.8369 Validation Accuracy: 0.578600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.9627 Validation Accuracy: 0.580600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     2.3553 Validation Accuracy: 0.547600\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     2.1859 Validation Accuracy: 0.564600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     2.1143 Validation Accuracy: 0.574000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     2.3696 Validation Accuracy: 0.548600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     2.2448 Validation Accuracy: 0.568200\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     2.3524 Validation Accuracy: 0.555800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     2.3916 Validation Accuracy: 0.562600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     2.3851 Validation Accuracy: 0.569200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     2.4926 Validation Accuracy: 0.555800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     2.5082 Validation Accuracy: 0.554000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     2.5586 Validation Accuracy: 0.553800\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     2.5286 Validation Accuracy: 0.570800\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     2.5486 Validation Accuracy: 0.566600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     2.4552 Validation Accuracy: 0.569000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     2.6058 Validation Accuracy: 0.552200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     2.5882 Validation Accuracy: 0.554000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     2.7108 Validation Accuracy: 0.542200\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     2.5673 Validation Accuracy: 0.564800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     2.7328 Validation Accuracy: 0.554400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     2.7590 Validation Accuracy: 0.544400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     3.0196 Validation Accuracy: 0.534200\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     2.6753 Validation Accuracy: 0.562600\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     2.8396 Validation Accuracy: 0.542000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     2.9521 Validation Accuracy: 0.541800\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     2.6771 Validation Accuracy: 0.575800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     2.7127 Validation Accuracy: 0.579600\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     2.7345 Validation Accuracy: 0.585200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     2.8376 Validation Accuracy: 0.588800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     2.9677 Validation Accuracy: 0.581600\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     2.9451 Validation Accuracy: 0.586400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     2.9684 Validation Accuracy: 0.584000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     3.0246 Validation Accuracy: 0.584600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     2.9269 Validation Accuracy: 0.584400\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     3.0627 Validation Accuracy: 0.581600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     3.0016 Validation Accuracy: 0.587600\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     3.0332 Validation Accuracy: 0.583200\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     3.1667 Validation Accuracy: 0.585600\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     3.0713 Validation Accuracy: 0.581000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     3.1346 Validation Accuracy: 0.580200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     3.1963 Validation Accuracy: 0.571200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     3.0929 Validation Accuracy: 0.585000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     3.2740 Validation Accuracy: 0.583800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     3.1692 Validation Accuracy: 0.585200\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     3.2710 Validation Accuracy: 0.577600\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     3.1355 Validation Accuracy: 0.584000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     3.1333 Validation Accuracy: 0.580400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     1.8815 Validation Accuracy: 0.334600\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.6022 Validation Accuracy: 0.410600\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.5636 Validation Accuracy: 0.427200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.4260 Validation Accuracy: 0.480200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.3706 Validation Accuracy: 0.504400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.3705 Validation Accuracy: 0.503200\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.2763 Validation Accuracy: 0.545800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.3518 Validation Accuracy: 0.512800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.2208 Validation Accuracy: 0.570400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.2468 Validation Accuracy: 0.557000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.2572 Validation Accuracy: 0.555400\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.2234 Validation Accuracy: 0.574400\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.1662 Validation Accuracy: 0.590600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.1412 Validation Accuracy: 0.596600\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.1484 Validation Accuracy: 0.599800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.1268 Validation Accuracy: 0.600600\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.1021 Validation Accuracy: 0.618600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.0746 Validation Accuracy: 0.619000\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.1201 Validation Accuracy: 0.616200\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.0672 Validation Accuracy: 0.626800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.1006 Validation Accuracy: 0.617600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.0743 Validation Accuracy: 0.626200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.0350 Validation Accuracy: 0.638200\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.1137 Validation Accuracy: 0.616800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.0008 Validation Accuracy: 0.652800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.0510 Validation Accuracy: 0.636200\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.0332 Validation Accuracy: 0.645600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.0279 Validation Accuracy: 0.649400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.0645 Validation Accuracy: 0.637400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.0421 Validation Accuracy: 0.641600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.0115 Validation Accuracy: 0.654200\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.0392 Validation Accuracy: 0.644800\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.0306 Validation Accuracy: 0.651600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.0606 Validation Accuracy: 0.643400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.0284 Validation Accuracy: 0.657800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.0259 Validation Accuracy: 0.658600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.0513 Validation Accuracy: 0.651800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.0068 Validation Accuracy: 0.668800\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.0267 Validation Accuracy: 0.653200\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.0319 Validation Accuracy: 0.660400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.0865 Validation Accuracy: 0.642200\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.0563 Validation Accuracy: 0.661400\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.0288 Validation Accuracy: 0.656600\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.0281 Validation Accuracy: 0.668400\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.0338 Validation Accuracy: 0.669000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.1744 Validation Accuracy: 0.630400\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.0790 Validation Accuracy: 0.659600\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.2478 Validation Accuracy: 0.596400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.0905 Validation Accuracy: 0.656800\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.0399 Validation Accuracy: 0.669600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.0691 Validation Accuracy: 0.658600\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.0974 Validation Accuracy: 0.657800\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.1919 Validation Accuracy: 0.633200\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.1101 Validation Accuracy: 0.653000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.1639 Validation Accuracy: 0.649600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.0961 Validation Accuracy: 0.647600\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.1924 Validation Accuracy: 0.645400\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.1331 Validation Accuracy: 0.661200\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.1520 Validation Accuracy: 0.648000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.2593 Validation Accuracy: 0.634400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.3286 Validation Accuracy: 0.619200\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.2352 Validation Accuracy: 0.638400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.1805 Validation Accuracy: 0.656800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.2211 Validation Accuracy: 0.654600\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.3316 Validation Accuracy: 0.643400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.2525 Validation Accuracy: 0.641000\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.3460 Validation Accuracy: 0.631200\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.3029 Validation Accuracy: 0.640000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.1861 Validation Accuracy: 0.660200\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.3200 Validation Accuracy: 0.650200\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.3201 Validation Accuracy: 0.638200\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.3726 Validation Accuracy: 0.637400\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.2654 Validation Accuracy: 0.649000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.3279 Validation Accuracy: 0.638200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.4150 Validation Accuracy: 0.646000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.3063 Validation Accuracy: 0.655200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.2876 Validation Accuracy: 0.650600\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.2099 Validation Accuracy: 0.667400\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.4229 Validation Accuracy: 0.638800\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.4131 Validation Accuracy: 0.648400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.4170 Validation Accuracy: 0.660000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.3962 Validation Accuracy: 0.642800\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.2833 Validation Accuracy: 0.654400\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.3916 Validation Accuracy: 0.649600\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.4361 Validation Accuracy: 0.648000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.4687 Validation Accuracy: 0.652200\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.4597 Validation Accuracy: 0.640600\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.3905 Validation Accuracy: 0.645600\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.3993 Validation Accuracy: 0.657400\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.4195 Validation Accuracy: 0.662400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.5199 Validation Accuracy: 0.656600\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.5435 Validation Accuracy: 0.631200\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.4847 Validation Accuracy: 0.641200\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.4084 Validation Accuracy: 0.664200\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.5331 Validation Accuracy: 0.661600\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.5942 Validation Accuracy: 0.646600\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.6731 Validation Accuracy: 0.625400\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.5722 Validation Accuracy: 0.640200\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.5142 Validation Accuracy: 0.659600\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.6341 Validation Accuracy: 0.653600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.6401 Validation Accuracy: 0.640800\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.7011 Validation Accuracy: 0.639400\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.6529 Validation Accuracy: 0.645400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.6274 Validation Accuracy: 0.661200\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.7441 Validation Accuracy: 0.653600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.6736 Validation Accuracy: 0.652200\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.6464 Validation Accuracy: 0.657800\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.7144 Validation Accuracy: 0.646400\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.6894 Validation Accuracy: 0.658400\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.8249 Validation Accuracy: 0.660600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.6878 Validation Accuracy: 0.653600\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.6565 Validation Accuracy: 0.651000\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.7832 Validation Accuracy: 0.638800\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.7259 Validation Accuracy: 0.660600\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.8615 Validation Accuracy: 0.660000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.9457 Validation Accuracy: 0.640400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.7092 Validation Accuracy: 0.653000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.7725 Validation Accuracy: 0.653400\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.8744 Validation Accuracy: 0.646600\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.8818 Validation Accuracy: 0.661600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.8937 Validation Accuracy: 0.655600\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.6906 Validation Accuracy: 0.659800\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.9218 Validation Accuracy: 0.640200\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.8197 Validation Accuracy: 0.652400\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     2.0058 Validation Accuracy: 0.649200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.9785 Validation Accuracy: 0.642400\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.7688 Validation Accuracy: 0.659200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.8771 Validation Accuracy: 0.652800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     2.0424 Validation Accuracy: 0.637000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     2.1618 Validation Accuracy: 0.644400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     2.0781 Validation Accuracy: 0.646400\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.9189 Validation Accuracy: 0.649400\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.9000 Validation Accuracy: 0.663800\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     2.0840 Validation Accuracy: 0.643400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     2.2043 Validation Accuracy: 0.652800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.9694 Validation Accuracy: 0.663000\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.8827 Validation Accuracy: 0.665400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.9725 Validation Accuracy: 0.659200\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     2.2781 Validation Accuracy: 0.630000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     2.1931 Validation Accuracy: 0.648600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     2.0282 Validation Accuracy: 0.655000\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.9907 Validation Accuracy: 0.663400\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     2.0202 Validation Accuracy: 0.656600\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     2.3301 Validation Accuracy: 0.631600\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     2.2136 Validation Accuracy: 0.646600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     2.0190 Validation Accuracy: 0.658800\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     2.1072 Validation Accuracy: 0.656000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     2.0147 Validation Accuracy: 0.661600\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     2.1953 Validation Accuracy: 0.653200\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     2.1944 Validation Accuracy: 0.650800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     2.0276 Validation Accuracy: 0.653800\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     2.0050 Validation Accuracy: 0.662000\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     2.0805 Validation Accuracy: 0.654800\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     2.1648 Validation Accuracy: 0.664200\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     2.2018 Validation Accuracy: 0.653600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     2.1870 Validation Accuracy: 0.653600\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     2.1730 Validation Accuracy: 0.654600\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     2.1745 Validation Accuracy: 0.655400\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     2.1335 Validation Accuracy: 0.663600\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     2.2857 Validation Accuracy: 0.659400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     2.1886 Validation Accuracy: 0.664800\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     2.3599 Validation Accuracy: 0.635800\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     2.1913 Validation Accuracy: 0.662000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     2.3116 Validation Accuracy: 0.666200\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     2.4042 Validation Accuracy: 0.650800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     2.3799 Validation Accuracy: 0.660000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     2.4974 Validation Accuracy: 0.635800\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     2.2989 Validation Accuracy: 0.654000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     2.2947 Validation Accuracy: 0.665000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     2.5643 Validation Accuracy: 0.646600\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     2.5984 Validation Accuracy: 0.639600\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     2.3430 Validation Accuracy: 0.652400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     2.2577 Validation Accuracy: 0.662800\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     2.2925 Validation Accuracy: 0.663000\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     2.4469 Validation Accuracy: 0.661600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     2.3665 Validation Accuracy: 0.654600\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     2.3603 Validation Accuracy: 0.643200\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     2.3291 Validation Accuracy: 0.668400\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     2.3486 Validation Accuracy: 0.659400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     2.4837 Validation Accuracy: 0.648800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     2.2490 Validation Accuracy: 0.655200\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     2.2644 Validation Accuracy: 0.652800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     2.3491 Validation Accuracy: 0.668000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     2.3102 Validation Accuracy: 0.663600\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     2.4621 Validation Accuracy: 0.659400\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     2.4700 Validation Accuracy: 0.651200\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     2.2931 Validation Accuracy: 0.656600\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     2.2832 Validation Accuracy: 0.662000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     2.4437 Validation Accuracy: 0.652200\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     2.3971 Validation Accuracy: 0.662800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     2.6420 Validation Accuracy: 0.642400\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     2.5254 Validation Accuracy: 0.658000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     2.4795 Validation Accuracy: 0.661200\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     2.3491 Validation Accuracy: 0.662400\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     2.5571 Validation Accuracy: 0.658400\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     2.4768 Validation Accuracy: 0.667600\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     2.5479 Validation Accuracy: 0.659800\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     2.3763 Validation Accuracy: 0.669200\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     2.5028 Validation Accuracy: 0.664000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     2.5618 Validation Accuracy: 0.649800\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     2.7137 Validation Accuracy: 0.646200\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     2.4016 Validation Accuracy: 0.664000\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     2.4315 Validation Accuracy: 0.670800\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     2.4832 Validation Accuracy: 0.667400\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     2.8092 Validation Accuracy: 0.641200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     2.6313 Validation Accuracy: 0.652000\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     2.4120 Validation Accuracy: 0.664400\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     2.5090 Validation Accuracy: 0.671200\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     2.6039 Validation Accuracy: 0.650800\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     2.5727 Validation Accuracy: 0.664200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     2.5751 Validation Accuracy: 0.662400\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     2.5084 Validation Accuracy: 0.664800\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     2.5819 Validation Accuracy: 0.655200\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     2.5561 Validation Accuracy: 0.654800\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     2.8008 Validation Accuracy: 0.653200\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     2.6466 Validation Accuracy: 0.662800\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     2.6579 Validation Accuracy: 0.660200\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     2.5565 Validation Accuracy: 0.662800\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     2.7364 Validation Accuracy: 0.658000\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     2.6798 Validation Accuracy: 0.654800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     2.5869 Validation Accuracy: 0.663800\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     2.6896 Validation Accuracy: 0.666400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     2.6745 Validation Accuracy: 0.661200\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     2.5940 Validation Accuracy: 0.659000\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     2.7350 Validation Accuracy: 0.656600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     2.7272 Validation Accuracy: 0.665000\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     2.7539 Validation Accuracy: 0.666600\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     2.6525 Validation Accuracy: 0.666200\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     2.5551 Validation Accuracy: 0.664400\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     2.6936 Validation Accuracy: 0.659000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     2.7330 Validation Accuracy: 0.663400\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     2.6693 Validation Accuracy: 0.671200\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     2.7992 Validation Accuracy: 0.652400\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     2.6865 Validation Accuracy: 0.658600\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     2.9376 Validation Accuracy: 0.653000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     2.6797 Validation Accuracy: 0.670400\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     2.8669 Validation Accuracy: 0.660000\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     2.7645 Validation Accuracy: 0.660200\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     2.7294 Validation Accuracy: 0.664800\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     2.8857 Validation Accuracy: 0.660000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     2.7303 Validation Accuracy: 0.672200\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     2.9093 Validation Accuracy: 0.665600\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     2.8915 Validation Accuracy: 0.654000\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     2.8573 Validation Accuracy: 0.650600\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     2.9880 Validation Accuracy: 0.647000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     2.9594 Validation Accuracy: 0.651200\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     3.1068 Validation Accuracy: 0.660800\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     2.8510 Validation Accuracy: 0.655000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     2.7723 Validation Accuracy: 0.659400\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     2.9452 Validation Accuracy: 0.651800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     2.7302 Validation Accuracy: 0.671400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     2.9305 Validation Accuracy: 0.660200\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     2.7941 Validation Accuracy: 0.656000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     2.9361 Validation Accuracy: 0.636400\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     2.9910 Validation Accuracy: 0.650000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     2.7431 Validation Accuracy: 0.662400\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     2.9393 Validation Accuracy: 0.663600\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     2.6550 Validation Accuracy: 0.668000\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     2.8660 Validation Accuracy: 0.666200\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     2.8893 Validation Accuracy: 0.655400\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     2.6200 Validation Accuracy: 0.674800\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     2.9225 Validation Accuracy: 0.659400\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     2.6860 Validation Accuracy: 0.672800\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     2.9434 Validation Accuracy: 0.663400\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     2.9732 Validation Accuracy: 0.656600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     2.8411 Validation Accuracy: 0.670600\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     2.8522 Validation Accuracy: 0.657200\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     2.8904 Validation Accuracy: 0.657200\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     2.9270 Validation Accuracy: 0.657000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     2.9973 Validation Accuracy: 0.646800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     2.9224 Validation Accuracy: 0.672800\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     2.9168 Validation Accuracy: 0.666200\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     2.7214 Validation Accuracy: 0.668200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     2.8528 Validation Accuracy: 0.653400\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     2.9433 Validation Accuracy: 0.660800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     3.0369 Validation Accuracy: 0.673800\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     3.0486 Validation Accuracy: 0.657200\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     2.8622 Validation Accuracy: 0.665800\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     2.9411 Validation Accuracy: 0.657400\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     2.8441 Validation Accuracy: 0.665600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     2.9858 Validation Accuracy: 0.667600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     2.8920 Validation Accuracy: 0.658400\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     2.8757 Validation Accuracy: 0.652600\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     3.0774 Validation Accuracy: 0.657400\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     2.8773 Validation Accuracy: 0.667000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     2.9626 Validation Accuracy: 0.663600\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     3.0485 Validation Accuracy: 0.662200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     3.0633 Validation Accuracy: 0.656600\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     3.0329 Validation Accuracy: 0.654600\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     2.9582 Validation Accuracy: 0.663000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     2.9781 Validation Accuracy: 0.663800\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     3.0042 Validation Accuracy: 0.670200\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     2.9790 Validation Accuracy: 0.651200\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     2.9076 Validation Accuracy: 0.657400\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     3.0568 Validation Accuracy: 0.655800\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     2.9538 Validation Accuracy: 0.666600\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     2.9939 Validation Accuracy: 0.659600\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     3.2029 Validation Accuracy: 0.648800\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     3.0693 Validation Accuracy: 0.653400\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     3.0450 Validation Accuracy: 0.660800\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     2.9735 Validation Accuracy: 0.672000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     2.9162 Validation Accuracy: 0.668800\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     3.1523 Validation Accuracy: 0.656200\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     3.0937 Validation Accuracy: 0.658800\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     2.9874 Validation Accuracy: 0.666600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     2.9094 Validation Accuracy: 0.669000\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     2.9971 Validation Accuracy: 0.659800\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     2.9047 Validation Accuracy: 0.655800\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     2.9947 Validation Accuracy: 0.657800\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     3.0090 Validation Accuracy: 0.660400\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     2.9240 Validation Accuracy: 0.668000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     2.8939 Validation Accuracy: 0.674600\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     2.9322 Validation Accuracy: 0.660800\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     3.0603 Validation Accuracy: 0.650600\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     3.0008 Validation Accuracy: 0.660000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     2.9664 Validation Accuracy: 0.669600\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     2.8117 Validation Accuracy: 0.665800\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     3.0254 Validation Accuracy: 0.664600\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     2.9981 Validation Accuracy: 0.662400\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     3.0683 Validation Accuracy: 0.660000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     2.9741 Validation Accuracy: 0.666000\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     3.0756 Validation Accuracy: 0.665600\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     3.1262 Validation Accuracy: 0.654800\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     3.1228 Validation Accuracy: 0.655200\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     2.9411 Validation Accuracy: 0.662800\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     3.0846 Validation Accuracy: 0.666600\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     2.9064 Validation Accuracy: 0.671600\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     3.1326 Validation Accuracy: 0.657000\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     2.9543 Validation Accuracy: 0.666600\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     3.1795 Validation Accuracy: 0.667400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     3.2163 Validation Accuracy: 0.665400\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     3.0748 Validation Accuracy: 0.669400\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     3.0063 Validation Accuracy: 0.668400\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     3.0193 Validation Accuracy: 0.657600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     3.1468 Validation Accuracy: 0.661200\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     3.1198 Validation Accuracy: 0.664200\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     2.9216 Validation Accuracy: 0.667800\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     3.0664 Validation Accuracy: 0.669200\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     2.9743 Validation Accuracy: 0.659600\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     3.0932 Validation Accuracy: 0.662800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     3.0283 Validation Accuracy: 0.665800\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     3.1875 Validation Accuracy: 0.656600\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     3.0620 Validation Accuracy: 0.666400\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     2.9224 Validation Accuracy: 0.680000\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     3.2041 Validation Accuracy: 0.660000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     3.0927 Validation Accuracy: 0.668200\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     3.0795 Validation Accuracy: 0.667400\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     3.0782 Validation Accuracy: 0.663200\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     3.0387 Validation Accuracy: 0.660200\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     3.2831 Validation Accuracy: 0.655400\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     3.1593 Validation Accuracy: 0.664200\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     3.1523 Validation Accuracy: 0.657600\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     2.9708 Validation Accuracy: 0.666000\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     2.9060 Validation Accuracy: 0.665000\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     3.0284 Validation Accuracy: 0.662800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     3.0616 Validation Accuracy: 0.657800\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     3.0813 Validation Accuracy: 0.656200\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     3.0796 Validation Accuracy: 0.668000\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     3.2913 Validation Accuracy: 0.659000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     3.1424 Validation Accuracy: 0.665400\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     3.2347 Validation Accuracy: 0.664000\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     3.3237 Validation Accuracy: 0.658000\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     3.2233 Validation Accuracy: 0.654400\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     3.2461 Validation Accuracy: 0.653800\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     3.2182 Validation Accuracy: 0.663000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     3.2207 Validation Accuracy: 0.666200\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     3.2190 Validation Accuracy: 0.675400\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     3.2188 Validation Accuracy: 0.667600\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     3.2113 Validation Accuracy: 0.669600\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     3.5035 Validation Accuracy: 0.662000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     3.2802 Validation Accuracy: 0.663200\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     3.2202 Validation Accuracy: 0.667800\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     3.2104 Validation Accuracy: 0.671800\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     3.2206 Validation Accuracy: 0.658800\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     3.2077 Validation Accuracy: 0.664400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Lets Test the model against the test dataset.  This will be our final accuracy. we should have an accuracy greater than 50%. If we don't, we'll keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6693359375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArsAAAJ/CAYAAAB4GhsgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1v8HQfuGFKhES9AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf602c1f28>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 349
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 67% Accuracy?\n",
    "You might be wondering why we can't get an accuracy any higher. First things first, 67% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't learned all there is to know about neural networks. We still need to cover a few more techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
